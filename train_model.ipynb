{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ImbalancedClassSampler(WeightedRandomSampler):\n",
    "\n",
    "    def __init__(self,\n",
    "                 dataset: Dataset,\n",
    "                 length: int,\n",
    "                 replacement: bool = True):\n",
    "        labels = torch.tensor([label for _, label in dataset])\n",
    "\n",
    "        class_count = torch.bincount(labels.squeeze())\n",
    "        class_weighting = 1. / class_count\n",
    "        sample_weights = class_weighting[labels]\n",
    "\n",
    "        super().__init__(sample_weights, length, replacement=replacement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Optional\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Transformed(Dataset):\n",
    "\n",
    "    def __init__(self, dataset: Dataset, transform: Optional[Callable] = None):\n",
    "        \"\"\"Add a transform to a dataset that does not support transforms.\n",
    "\n",
    "        Args:\n",
    "            dataset (Dataset): The dataset to use.\n",
    "            transform (Optional[Callable], optional): Transform to apply to each sample's data. Defaults to None.\n",
    "        \"\"\"\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        X, y = self.dataset[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            X = self.transform(X)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentedFood(Dataset):\n",
    "    def __init__(self, data_dir: str, min_samples = 10, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.classes = []\n",
    "\n",
    "        class_names = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        for class_name in class_names:\n",
    "            class_dir = os.path.join(self.data_dir, class_name)\n",
    "\n",
    "            files_per_class = []\n",
    "            labels_per_class = []\n",
    "\n",
    "            for file_name in os.listdir(class_dir):\n",
    "                if file_name.endswith(\".png\"):\n",
    "                    file_path = os.path.join(class_dir, file_name)\n",
    "                    files_per_class.append(file_path)\n",
    "                    labels_per_class.append(i)\n",
    "\n",
    "            if len(files_per_class) > min_samples:\n",
    "                self.data.extend(files_per_class)\n",
    "                self.labels.extend(labels_per_class)\n",
    "                self.classes.append(class_name)\n",
    "\n",
    "                i += 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        img = Image.open(self.data[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "data_dir = \"./train_final\"\n",
    "\n",
    "basic_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(256),\n",
    "])\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    basic_transforms,\n",
    "    transforms.RandomRotation(degrees=(0, 180)),\n",
    "    transforms.RandomCrop(224),\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    basic_transforms,\n",
    "    transforms.CenterCrop(224)\n",
    "])\n",
    "\n",
    "\n",
    "dataset = SegmentedFood(data_dir, 100)\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [0.8, 0.2])\n",
    "train_sampler = ImbalancedClassSampler(train_dataset, int(8600 * 0.8))\n",
    "val_sampler = ImbalancedClassSampler(val_dataset, int(8600 * 0.2))\n",
    "train_dataset = Transformed(train_dataset, train_transforms)\n",
    "val_dataset = Transformed(val_dataset, val_transforms)\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=batch_size,sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = models.resnet50(weights=models.ResNet50_Weights)\n",
    "\n",
    "num_classes = len(dataset.classes)\n",
    "\n",
    "for param in resnet50.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "resnet50.fc = nn.Linear(resnet50.fc.in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_dir_path = f\"nets/\"\n",
    "if not os.path.exists(model_save_dir_path):\n",
    "    os.makedirs(model_save_dir_path)\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "resnet50.to(device)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet50.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(60):\n",
    "    # train\n",
    "    train_error = 0.0\n",
    "    train_accuracy = 0.0\n",
    "    with torch.set_grad_enabled(True):\n",
    "        resnet50.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_data_loader):\n",
    "            # # #Â break after  first batch\n",
    "            # if batch_idx == 1:\n",
    "            #     break\n",
    "            optimizer.zero_grad()\n",
    "            output = resnet50(data)\n",
    "            prediction = output.argmax(dim=1).view(target.shape)\n",
    "            accuracy = (prediction == target).sum().float() / target.size(0)\n",
    "            error = loss(output, target)\n",
    "\n",
    "            error.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_error += error.detach()\n",
    "            train_accuracy += accuracy\n",
    "\n",
    "        print(\"train loss\", train_error.item() / len(train_data_loader), \"train acc\", train_accuracy.item() / len(train_data_loader))\n",
    "\n",
    "    # save model\n",
    "    torch.save(resnet50.state_dict(), os.path.join(model_save_dir_path, f\"resnet50_{epoch}.pth\"))\n",
    "    \n",
    "    # validate\n",
    "    with torch.set_grad_enabled(False):\n",
    "        resnet50.eval()\n",
    "        eval_error = 0.0\n",
    "        eval_accuracy = 0.0\n",
    "        preds = []\n",
    "        labels = []\n",
    "        for batch_idx, (data, target) in enumerate(val_data_loader):\n",
    "            # break after  first batch\n",
    "            # if batch_idx == 1:\n",
    "            #     break\n",
    "            output = resnet50(data)\n",
    "            prediction = output.argmax(dim=1).view(target.shape)\n",
    "            accuracy = (prediction == target).sum().float() / target.size(0)\n",
    "            error = loss(output, target)\n",
    "\n",
    "            eval_error += error.detach()\n",
    "            eval_accuracy += accuracy\n",
    "\n",
    "            preds.append(prediction)\n",
    "            labels.append(target)\n",
    "\n",
    "        preds = torch.cat(preds)\n",
    "        labels = torch.cat(labels)\n",
    "\n",
    "        print(\"eval loss\", (eval_error.item() / len(val_data_loader), \"train acc\", eval_accuracy.item() / len(val_data_loader)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
